{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 8 - ARIMA: Stock Prices\n",
    "\n",
    "Allen Ansari, Chris Ballenger, Shantanu Godbole, Chad Madding\n",
    "\n",
    "DS 7333 Quantifying the World\n",
    "\n",
    "June 22, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using XGBoost in Python\n",
    "First of all, just like what you do with any other dataset, you are going to import the dataset and store it in a variable called case8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n1   4       1  1.630686  7.464411  C  4.145098   9.191265  2.436402  2.483921   \n2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n4   8       1  1.630686  7.464411  C  4.145098   8.742359  2.436402  2.483921   \n\n         v8  ...      v122      v123      v124  v125      v126      v127  \\\n0  0.012941  ...  8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n1  2.301630  ...  6.822439  3.549938  0.598896    AF  1.672658  3.239542   \n2  0.019645  ...  9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n3  0.171947  ...  7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n4  1.496569  ...  6.822439  3.549938  0.919812     Z  1.672658  3.239542   \n\n       v128  v129      v130      v131  \n0  2.024285     0  0.636365  2.857144  \n1  1.957825     0  1.925763  1.739389  \n2  1.120468     2  0.883118  1.176472  \n3  1.990847     1  1.677108  1.034483  \n4  2.030373     0  1.925763  1.739389  \n\n[5 rows x 133 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>target</th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>v3</th>\n      <th>v4</th>\n      <th>v5</th>\n      <th>v6</th>\n      <th>v7</th>\n      <th>v8</th>\n      <th>...</th>\n      <th>v122</th>\n      <th>v123</th>\n      <th>v124</th>\n      <th>v125</th>\n      <th>v126</th>\n      <th>v127</th>\n      <th>v128</th>\n      <th>v129</th>\n      <th>v130</th>\n      <th>v131</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1.335739</td>\n      <td>8.727474</td>\n      <td>C</td>\n      <td>3.921026</td>\n      <td>7.915266</td>\n      <td>2.599278</td>\n      <td>3.176895</td>\n      <td>0.012941</td>\n      <td>...</td>\n      <td>8.000000</td>\n      <td>1.989780</td>\n      <td>0.035754</td>\n      <td>AU</td>\n      <td>1.804126</td>\n      <td>3.113719</td>\n      <td>2.024285</td>\n      <td>0</td>\n      <td>0.636365</td>\n      <td>2.857144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1.630686</td>\n      <td>7.464411</td>\n      <td>C</td>\n      <td>4.145098</td>\n      <td>9.191265</td>\n      <td>2.436402</td>\n      <td>2.483921</td>\n      <td>2.301630</td>\n      <td>...</td>\n      <td>6.822439</td>\n      <td>3.549938</td>\n      <td>0.598896</td>\n      <td>AF</td>\n      <td>1.672658</td>\n      <td>3.239542</td>\n      <td>1.957825</td>\n      <td>0</td>\n      <td>1.925763</td>\n      <td>1.739389</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>1</td>\n      <td>0.943877</td>\n      <td>5.310079</td>\n      <td>C</td>\n      <td>4.410969</td>\n      <td>5.326159</td>\n      <td>3.979592</td>\n      <td>3.928571</td>\n      <td>0.019645</td>\n      <td>...</td>\n      <td>9.333333</td>\n      <td>2.477596</td>\n      <td>0.013452</td>\n      <td>AE</td>\n      <td>1.773709</td>\n      <td>3.922193</td>\n      <td>1.120468</td>\n      <td>2</td>\n      <td>0.883118</td>\n      <td>1.176472</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>1</td>\n      <td>0.797415</td>\n      <td>8.304757</td>\n      <td>C</td>\n      <td>4.225930</td>\n      <td>11.627438</td>\n      <td>2.097700</td>\n      <td>1.987549</td>\n      <td>0.171947</td>\n      <td>...</td>\n      <td>7.018256</td>\n      <td>1.812795</td>\n      <td>0.002267</td>\n      <td>CJ</td>\n      <td>1.415230</td>\n      <td>2.954381</td>\n      <td>1.990847</td>\n      <td>1</td>\n      <td>1.677108</td>\n      <td>1.034483</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>1</td>\n      <td>1.630686</td>\n      <td>7.464411</td>\n      <td>C</td>\n      <td>4.145098</td>\n      <td>8.742359</td>\n      <td>2.436402</td>\n      <td>2.483921</td>\n      <td>1.496569</td>\n      <td>...</td>\n      <td>6.822439</td>\n      <td>3.549938</td>\n      <td>0.919812</td>\n      <td>Z</td>\n      <td>1.672658</td>\n      <td>3.239542</td>\n      <td>2.030373</td>\n      <td>0</td>\n      <td>1.925763</td>\n      <td>1.739389</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 133 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "case8 = pd.read_csv (r'data\\case_8.csv')\n",
    "\n",
    "case8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding of categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "case8 = pd.get_dummies(case8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check for its keys using the .keys() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['ID', 'target', 'v1', 'v2', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9',\n       ...\n       'v125_Q', 'v125_R', 'v125_S', 'v125_T', 'v125_U', 'v125_V', 'v125_W',\n       'v125_X', 'v125_Y', 'v125_Z'],\n      dtype='object', length=18688)\n"
    }
   ],
   "source": [
    "print (case8.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily check for its shape by using the case8.shape attribute, which will return the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(114321, 18688)\n"
    }
   ],
   "source": [
    "print (case8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see it returned (114321, 18688), that means there are 114321 rows of data with 18688 columns. The original data set contained 133 columns, after One Hot Encoding the count is now up to 18688."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the .info() method on your DataFrame to get useful information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 114321 entries, 0 to 114320\nColumns: 18688 entries, ID to v125_Z\ndtypes: float64(108), int64(6), uint8(18574)\nmemory usage: 2.1 GB\n"
    }
   ],
   "source": [
    "case8.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more summary statistics of the different features in the dataset we use the describe() method on the case8 DataFrame.\n",
    "\n",
    "**Note** - describe() only gives summary statistics of columns which are continuous in nature and not categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case8.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build the model using Trees as base learners (which are the default base learners) using XGBoost's scikit-learn compatible API. Along the way, we will also use some of the common tuning parameters which XGBoost provides in order to improve our model's performance, and using the root mean squared error (RMSE) performance metric to check the performance of the trained model on the test set. Root mean Squared error is the square root of the mean of the squared differences between the actual and the predicted values. We start by importing the library xgboost and other important libraries that we will be using for building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sparce matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sparse module from SciPy package \n",
    "from scipy import sparse\n",
    "# import uniform module to create random numbers\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "case8_spr = sparse.csr_matrix(case8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable and rest of the variables using .iloc to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = case8_spr.iloc[:,:-1],case8_spr.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 15.9 GiB for an array with shape (114321, 18687) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9eb0493b7cf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input data can not be a list.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         data, feature_names, feature_types = _convert_dataframes(\n\u001b[0m\u001b[0;32m    520\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_convert_dataframes\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    414\u001b[0m def _convert_dataframes(data, feature_names, feature_types,\n\u001b[0;32m    415\u001b[0m                         meta=None, meta_type=None):\n\u001b[1;32m--> 416\u001b[1;33m     data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0m\u001b[0;32m    417\u001b[0m                                                             \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                                                             \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_type\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmeta_type\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'float'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 15.9 GiB for an array with shape (114321, 18687) and data type float64"
     ]
    }
   ],
   "source": [
    "case8_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the train and test set for cross-validation of the results using the train_test_split function from sklearn's model_selection module with test_size size equal to 20% of the data. Also, to maintain reproducibility of the results, a random_state is also assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
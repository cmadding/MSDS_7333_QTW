{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RF and SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "with open(os.path.join(\"..\",\"data\",\"case_8_final_feats.pkl\"),\"rb\") as f:\n",
    "    y, case_8_reduced_feats = pickle.load(f)\n",
    "\n",
    "X = case_8_reduced_feats.values\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        stratify=y, \n",
    "        test_size=0.30,\n",
    "        random_state=123\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import timeit\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Done 108 out of 108 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-806ee00f657e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Elapsed time required for grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0melapsed_rf_nonparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mRF_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_rfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_features\" : [\"auto\",\"log2\",0.20, 0.30],\n",
    "    \"n_estimators\" : [10,50,100],\n",
    "    \"min_samples_leaf\" : [25, 50, 100]\n",
    "}\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=3,n_jobs = -2, verbose=1)\n",
    "CV_rfc_mod = CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "#Elapsed time required for grid search\n",
    "elapsed_rf_nonparallel = timeit.default_timer() - start_time\n",
    "\n",
    "RF_score = CV_rfc.score(X_test,y_test)\n",
    "RF_ypred = CV_rfc.predict(X_test)\n",
    "RFCV_matrix = metrics.confusion_matrix(y_test, RF_ypred)\n",
    "\n",
    "print('Random Forest GridSearch Accuracy: ', RF_score)\n",
    "print('Random Forest Matrix: ', RFCV_matrix)\n",
    "print('Best Parameter: ', CV_rfc.best_params_)\n",
    "print('\\nClassification report')\n",
    "print(classification_report(y_test,RF_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gridsearch2 = pd.DataFrame(CV_rfc.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gridsearch2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy Heatmap\n",
    "# import seaborn as sns\n",
    "\n",
    "# max_scores1 = df_gridsearch2.groupby(['param_n_estimators', \n",
    "#                                     'param_max_depth']).max()\n",
    "\n",
    "# max_scores2 = max_scores1.unstack()[['mean_test_score']]\n",
    "\n",
    "# plt.figure(figsize = (16,10))\n",
    "\n",
    "# plt.title('Model Accuracy', \n",
    "#               fontsize=14)\n",
    "\n",
    "# sns.heatmap(max_scores2.mean_test_score, annot=True, fmt='.7g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(CV_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"CV_Random_Forest.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_rfc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_cv = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pickle_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=0.3, min_samples_leaf=25, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('capstone': conda)",
   "language": "python",
   "name": "python37064bitcapstoneconda433aed4549574e2f807458347f00c8aa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

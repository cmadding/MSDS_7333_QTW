{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "project_folder = \".\"\n",
    "\n",
    "with open(os.path.join(project_folder,\"data\",\"train_test.pkl\"), \"rb\") as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.coo.coo_matrix"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.toarray()\n",
    "X_test_np = (X_test.toarray()) \n",
    "\n",
    "\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np  = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "np_data_scaled = sc.fit_transform(X_train_np)\n",
    "np_data_scaled_test = sc.transform(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.utils import normalize, to_categorical\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               34500     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 215,001\n",
      "Trainable params: 215,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(68,)))\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(300))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_auc', mode='max', min_delta = 0.0001 , patience = 10,restore_best_weights=True)\n",
    "\n",
    "callbacks_a = [earlyStopping]\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = 'binary_crossentropy', metrics = [tf.keras.metrics.AUC(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/1000\n",
      "128000/128000 [==============================] - 8s 63us/sample - loss: 0.3182 - auc: 0.9362 - recall: 0.8038 - val_loss: 0.2277 - val_auc: 0.9672 - val_recall: 0.8921\n",
      "Epoch 2/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.2071 - auc: 0.9731 - recall: 0.8940 - val_loss: 0.1898 - val_auc: 0.9777 - val_recall: 0.8849\n",
      "Epoch 3/1000\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.1745 - auc: 0.9804 - recall: 0.9171 - val_loss: 0.1580 - val_auc: 0.9837 - val_recall: 0.9383\n",
      "Epoch 4/1000\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.1575 - auc: 0.9837 - recall: 0.9259 - val_loss: 0.1550 - val_auc: 0.9839 - val_recall: 0.9289\n",
      "Epoch 5/1000\n",
      "128000/128000 [==============================] - 7s 56us/sample - loss: 0.1443 - auc: 0.9860 - recall: 0.9331 - val_loss: 0.1402 - val_auc: 0.9865 - val_recall: 0.9232\n",
      "Epoch 6/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1387 - auc: 0.9869 - recall: 0.9365 - val_loss: 0.1371 - val_auc: 0.9869 - val_recall: 0.9274\n",
      "Epoch 7/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1302 - auc: 0.9882 - recall: 0.9420 - val_loss: 0.1330 - val_auc: 0.9875 - val_recall: 0.9405\n",
      "Epoch 8/1000\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.1254 - auc: 0.9889 - recall: 0.9440 - val_loss: 0.1252 - val_auc: 0.9889 - val_recall: 0.9300\n",
      "Epoch 9/1000\n",
      "128000/128000 [==============================] - 8s 60us/sample - loss: 0.1234 - auc: 0.9891 - recall: 0.9462 - val_loss: 0.1295 - val_auc: 0.9879 - val_recall: 0.9317\n",
      "Epoch 10/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1181 - auc: 0.9898 - recall: 0.9489 - val_loss: 0.1322 - val_auc: 0.9875 - val_recall: 0.9308\n",
      "Epoch 11/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1130 - auc: 0.9905 - recall: 0.9492 - val_loss: 0.1282 - val_auc: 0.9882 - val_recall: 0.9525\n",
      "Epoch 12/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.1124 - auc: 0.9904 - recall: 0.9516 - val_loss: 0.1252 - val_auc: 0.9885 - val_recall: 0.9477\n",
      "Epoch 13/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.1089 - auc: 0.9911 - recall: 0.9528 - val_loss: 0.1255 - val_auc: 0.9886 - val_recall: 0.9323\n",
      "Epoch 14/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1072 - auc: 0.9913 - recall: 0.9533 - val_loss: 0.1163 - val_auc: 0.9900 - val_recall: 0.9575\n",
      "Epoch 15/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1037 - auc: 0.9918 - recall: 0.9561 - val_loss: 0.1203 - val_auc: 0.9899 - val_recall: 0.9597\n",
      "Epoch 16/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.1034 - auc: 0.9918 - recall: 0.9563 - val_loss: 0.1371 - val_auc: 0.9868 - val_recall: 0.9343\n",
      "Epoch 17/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.1012 - auc: 0.9921 - recall: 0.9570 - val_loss: 0.1210 - val_auc: 0.9894 - val_recall: 0.9564\n",
      "Epoch 18/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0988 - auc: 0.9924 - recall: 0.9584 - val_loss: 0.1185 - val_auc: 0.9895 - val_recall: 0.9485\n",
      "Epoch 19/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0972 - auc: 0.9925 - recall: 0.9584 - val_loss: 0.1282 - val_auc: 0.9883 - val_recall: 0.9525\n",
      "Epoch 20/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0963 - auc: 0.9925 - recall: 0.9594 - val_loss: 0.1249 - val_auc: 0.9886 - val_recall: 0.9417\n",
      "Epoch 21/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0928 - auc: 0.9930 - recall: 0.9608 - val_loss: 0.1126 - val_auc: 0.9903 - val_recall: 0.9587\n",
      "Epoch 22/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0919 - auc: 0.9931 - recall: 0.9620 - val_loss: 0.1158 - val_auc: 0.9896 - val_recall: 0.9503\n",
      "Epoch 23/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0914 - auc: 0.9932 - recall: 0.9613 - val_loss: 0.1216 - val_auc: 0.9892 - val_recall: 0.9528\n",
      "Epoch 24/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.0885 - auc: 0.9935 - recall: 0.9623 - val_loss: 0.1216 - val_auc: 0.9890 - val_recall: 0.9495\n",
      "Epoch 25/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.0885 - auc: 0.9935 - recall: 0.9635 - val_loss: 0.1147 - val_auc: 0.9900 - val_recall: 0.9545\n",
      "Epoch 26/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.0873 - auc: 0.9935 - recall: 0.9641 - val_loss: 0.1256 - val_auc: 0.9891 - val_recall: 0.9561\n",
      "Epoch 27/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0853 - auc: 0.9939 - recall: 0.9636 - val_loss: 0.1136 - val_auc: 0.9902 - val_recall: 0.9571\n",
      "Epoch 28/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0841 - auc: 0.9941 - recall: 0.9643 - val_loss: 0.1157 - val_auc: 0.9899 - val_recall: 0.9528\n",
      "Epoch 29/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.0833 - auc: 0.9941 - recall: 0.9643 - val_loss: 0.1176 - val_auc: 0.9898 - val_recall: 0.9529\n",
      "Epoch 30/1000\n",
      "128000/128000 [==============================] - 7s 57us/sample - loss: 0.0848 - auc: 0.9938 - recall: 0.9640 - val_loss: 0.1216 - val_auc: 0.9897 - val_recall: 0.9573\n",
      "Epoch 31/1000\n",
      "128000/128000 [==============================] - 7s 58us/sample - loss: 0.0797 - auc: 0.9945 - recall: 0.9658 - val_loss: 0.1177 - val_auc: 0.9898 - val_recall: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a506e3dd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN\n",
    "model.fit(np_data_scaled, y_train_np, batch_size = 256, validation_data=(np_data_scaled_test,y_test_np), epochs = 1000 , callbacks = callbacks_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np_data_scaled_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2316656e-05],\n",
       "       [9.9841070e-01],\n",
       "       [5.9143591e-01],\n",
       "       ...,\n",
       "       [1.8882751e-04],\n",
       "       [3.0104220e-03],\n",
       "       [3.3550262e-03]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np_data_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:56<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "probas = list(np.arange(0.01, 0.4, 0.01))\n",
    "\n",
    "def calcCost(model, X, y, proba, fp = 10, fn = 500):\n",
    "    y_hat_proba = model.predict(X,use_multiprocessing=True)\n",
    "    y_hat = (y_hat_proba > proba).astype(int)\n",
    "    mt = metrics.confusion_matrix(y, y_hat)\n",
    "    acc = metrics.accuracy_score(y, y_hat)\n",
    "    precision = metrics.precision_score(y, y_hat)\n",
    "    return {\n",
    "        \"probability\":proba,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"fn\":mt[1,0],\n",
    "        \"fn_cost\":mt[1,0]*fn,\n",
    "        \"fp\":mt[0,1],\n",
    "        \"fp_cost\":mt[0,1]*fp\n",
    "    }\n",
    "\n",
    "cost = [ calcCost(model, np_data_scaled_test, y_test, proba) for proba in tqdm(probas) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>fn</th>\n",
       "      <th>fn_cost</th>\n",
       "      <th>fp</th>\n",
       "      <th>fp_cost</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.889250</td>\n",
       "      <td>0.786326</td>\n",
       "      <td>103</td>\n",
       "      <td>51500</td>\n",
       "      <td>3441</td>\n",
       "      <td>34410</td>\n",
       "      <td>85910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.901937</td>\n",
       "      <td>0.807015</td>\n",
       "      <td>112</td>\n",
       "      <td>56000</td>\n",
       "      <td>3026</td>\n",
       "      <td>30260</td>\n",
       "      <td>86260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.870125</td>\n",
       "      <td>0.757230</td>\n",
       "      <td>93</td>\n",
       "      <td>46500</td>\n",
       "      <td>4063</td>\n",
       "      <td>40630</td>\n",
       "      <td>87130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.832875</td>\n",
       "      <td>0.706537</td>\n",
       "      <td>78</td>\n",
       "      <td>39000</td>\n",
       "      <td>5270</td>\n",
       "      <td>52700</td>\n",
       "      <td>91700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.910094</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>129</td>\n",
       "      <td>64500</td>\n",
       "      <td>2748</td>\n",
       "      <td>27480</td>\n",
       "      <td>91980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   probability  accuracy  precision   fn  fn_cost    fp  fp_cost  total_cost\n",
       "2         0.03  0.889250   0.786326  103    51500  3441    34410       85910\n",
       "3         0.04  0.901937   0.807015  112    56000  3026    30260       86260\n",
       "1         0.02  0.870125   0.757230   93    46500  4063    40630       87130\n",
       "0         0.01  0.832875   0.706537   78    39000  5270    52700       91700\n",
       "4         0.05  0.910094   0.821384  129    64500  2748    27480       91980"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cost_df = pd.DataFrame(cost)\n",
    "\n",
    "cost_df[\"total_cost\"] = cost_df.fn_cost + cost_df.fp_cost\n",
    "\n",
    "cost_df.sort_values(by=[\"total_cost\"], ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model_85.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:QTW] *",
   "language": "python",
   "name": "conda-env-QTW-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
